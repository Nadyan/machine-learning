{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Otimização de Modelos através de Hiperparâmetros - Parte 2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Let41XIt5e4"
      },
      "source": [
        "# Random Search\n",
        "\n",
        "Ao invés de explorarmos exaustivamente nosso espaço de parâmetros, escolhemos combinações aleatoriamente e as testamos no nosso estimador. Dessa forma, não precisamos explorar o espaço inteiro para encontrar combinações de hiperparâmetros boas o suficiente para o problema em que queremos resolver. Não encontraremos necessáriamente um minimo/máximo global, mas pelo menos um local suficiente.\n",
        "\n",
        "Diferente do GridSeatch que precisa de pontos específicos no espaço de parâmetros (1, 10, 25 ... n), o RandomSearch permite um espaço contínuo (0.5, 1, 2.558, 14 ... n)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eijTVQqts8eS"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "uri = \"https://gist.githubusercontent.com/guilhermesilveira/e99a526b2e7ccc6c3b70f53db43a87d2/raw/1605fc74aa778066bf2e6695e24d53cf65f2f447/machine-learning-carros-simulacao.csv\"\n",
        "\n",
        "dados = pd.read_csv(uri).drop(columns=[\"Unnamed: 0\"], axis=1)\n",
        "\n",
        "dados_azar = dados.sort_values('vendido', ascending = True)\n",
        "x_azar = dados_azar[['preco', 'idade_do_modelo', 'km_por_ano']]\n",
        "y_azar = dados_azar['vendido']\n",
        "\n",
        "def resultados_validacao_cruzada(busca, x, y):\n",
        "    scores = cross_val_score(busca, x_azar, y_azar, cv = KFold(n_splits = 5, shuffle = True))\n",
        "\n",
        "    intervalo_acuracia = [scores.mean()-(2*scores.std()), scores.mean()+(2*scores.std())]\n",
        "\n",
        "    print(\"Melhor combinação: \", busca.best_params_)\n",
        "    print(\"Resultados parciais: \", scores)\n",
        "    print(\"Média de acurácia: %.2f%%\" % (scores.mean() * 100))\n",
        "    print(\"Intervalo de acurácia: %.2f%% ~ %.2f%%\" % (intervalo_acuracia[0]*100, intervalo_acuracia[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0L_0XKlXR23E"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "## espaço de parametros com 36 combinações possíveis:\n",
        "## 2 x 3 x 3 x 2 = 36\n",
        "espaco_de_parametros = {\n",
        "    'max_depth' : [3, 5],\n",
        "    'min_samples_split' : [32, 64, 128],\n",
        "    'min_samples_leaf' : [32, 64, 128],\n",
        "    'criterion' : ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "busca = RandomizedSearchCV(DecisionTreeClassifier(),\n",
        "                           espaco_de_parametros,\n",
        "                           cv = KFold(n_splits = 5, shuffle = True),\n",
        "                           random_state = SEED,\n",
        "                           n_iter = 16) ## vamos rodar para apenas 16 combinações do espaço de 36\n",
        "busca.fit(x_azar, y_azar)\n",
        "\n",
        "resultados = pd.DataFrame(busca.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjoAvNt5W4Yk"
      },
      "source": [
        "Nested Cross Validation do modelo com cross_val_score:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PR9Ca1TJVqvj",
        "outputId": "f4310209-1c9a-4073-e8c5-580ca5ed37e4"
      },
      "source": [
        "resultados_validacao_cruzada(busca, x_azar, y_azar)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melhor combinação:  {'min_samples_split': 64, 'min_samples_leaf': 32, 'max_depth': 3, 'criterion': 'gini'}\n",
            "Resultados parciais:  [0.797  0.778  0.7915 0.774  0.7945]\n",
            "Média de acurácia: 78.70%\n",
            "Intervalo de acurácia: 76.85% ~ 80.55%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpwaow6LXy3d"
      },
      "source": [
        "Com a busca aleatória de apenas 16 combinações, obtivemos uma acurácia muito parecida com o Grid Search, na qual procura a combinação no espaço inteiro de parâmetros.\n",
        "\n",
        "# Customizando o espaço de parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qsh53u4EXFuT"
      },
      "source": [
        "from scipy.stats import randint\n",
        "\n",
        "# 7 x 96 x 96 x 2 = +129 mil combinações\n",
        "espaco_de_parametros = {\n",
        "    'max_depth' : [3, 5,10, 15, 20, 30, None],\n",
        "    'min_samples_split' : randint(32, 128), # toda vez que rodar devolve um numero aleatorio entre 32 e 128\n",
        "    'min_samples_leaf' : randint(32, 128),  # 128-32 = 96 números\n",
        "    'criterion' : ['entropy', 'gini']\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJpEsUjaZhBz"
      },
      "source": [
        "busca = RandomizedSearchCV(DecisionTreeClassifier(),\n",
        "                           espaco_de_parametros,\n",
        "                           cv = KFold(n_splits = 5, shuffle = True),\n",
        "                           random_state = SEED,\n",
        "                           n_iter = 16) ## vamos rodar para apenas 16 combinações do espaço de 129 mil\n",
        "busca.fit(x_azar, y_azar)\n",
        "\n",
        "resultados = pd.DataFrame(busca.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8F65chDapAz",
        "outputId": "cb7e3e3a-0197-48d4-b7d2-4bfed56dbbc9"
      },
      "source": [
        "resultados_validacao_cruzada(busca, x_azar, y_azar)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melhor combinação:  {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 71, 'min_samples_split': 100}\n",
            "Resultados parciais:  [0.784  0.773  0.78   0.7895 0.789 ]\n",
            "Média de acurácia: 78.31%\n",
            "Intervalo de acurácia: 77.08% ~ 79.54%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5_JimBUbBjd"
      },
      "source": [
        "Dessa forma, conseguimos extrair um bom resultado de um grid com mais de 129 mil combinações possíveis em muito menos tempo.\n",
        "\n",
        "**Resumão das combinações ordenadas da melhor acurácia para a pior com desvio padrão e os parâmetros geradores:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTHjKgXjarNs",
        "outputId": "02f2986a-462b-47b7-a07f-78b2de9b411e"
      },
      "source": [
        "resultados_ordenados_pela_media = resultados.sort_values(\"mean_test_score\", ascending=False)\n",
        "for indice, linha in resultados_ordenados_pela_media.iterrows():\n",
        "    print(\"%.3f%% +-(%.3f%%) %s\" % (linha.mean_test_score*100, linha.std_test_score*2, linha.params))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "78.700% +-(0.004%) {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 71, 'min_samples_split': 100}\n",
            "78.410% +-(0.010%) {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 73, 'min_samples_split': 72}\n",
            "78.410% +-(0.010%) {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 64, 'min_samples_split': 67}\n",
            "78.270% +-(0.011%) {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 125, 'min_samples_split': 59}\n",
            "78.100% +-(0.014%) {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 124, 'min_samples_split': 88}\n",
            "78.010% +-(0.004%) {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 74, 'min_samples_split': 58}\n",
            "77.930% +-(0.011%) {'criterion': 'entropy', 'max_depth': 15, 'min_samples_leaf': 126, 'min_samples_split': 84}\n",
            "77.860% +-(0.011%) {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 108, 'min_samples_split': 110}\n",
            "77.680% +-(0.011%) {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 100, 'min_samples_split': 84}\n",
            "77.660% +-(0.012%) {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 101, 'min_samples_split': 52}\n",
            "77.650% +-(0.012%) {'criterion': 'entropy', 'max_depth': 15, 'min_samples_leaf': 103, 'min_samples_split': 96}\n",
            "77.640% +-(0.012%) {'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 104, 'min_samples_split': 88}\n",
            "77.600% +-(0.007%) {'criterion': 'entropy', 'max_depth': 15, 'min_samples_leaf': 93, 'min_samples_split': 111}\n",
            "77.600% +-(0.014%) {'criterion': 'gini', 'max_depth': 20, 'min_samples_leaf': 52, 'min_samples_split': 80}\n",
            "77.550% +-(0.008%) {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 88, 'min_samples_split': 78}\n",
            "77.430% +-(0.014%) {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 46, 'min_samples_split': 62}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsC0ac59fZZZ"
      },
      "source": [
        "Ou seja, quando comparado com o GridSearch, o RandomSearch tem uma vantagem bem grande que é o tempo de execução. Aumentando um pouco o espaço de parâmetros a gente aumenta considerávelmente o tempo de execução para o GridSearch, deixando essa execução muitas vezes inviável. Dessa forma, o RandomSearch consegue encontrar um resultado muito bom e parecido com muito menos tempo de processamento."
      ]
    }
  ]
}